{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 4\n",
    "\n",
    "Yay! It's week 4. This week we only have three components with very little reading. \n",
    "\n",
    "\n",
    "## Overview\n",
    "\n",
    "* A video lecture with a few questions\n",
    "* An exercise on visualizing geodata using a different set of tools from the ones we played with during Lecture 2.\n",
    "* Thinking about visualization, data quality, and binning. Why ***looking at the details of the data before applying fancy methods*** is often important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: More lecturing on dataviz\n",
    "\n",
    "We begin today by learning more about the theory of visualization, digging into data encodings and representations.\n",
    "\n",
    "[![IMAGE ALT TEXT HERE](https://img.youtube.com/vi/zE6Nr8trdrw/0.jpg)](https://www.youtube.com/watch?v=zE6Nr8trdrw)\n",
    "\n",
    "> *Excercise:* Some questions about the video\n",
    ">\n",
    "> * Mention 10 examples of ways we can encode data.\n",
    "> * Are all encodings created equally? Why not? Can you think of an example from the previous lectures?\n",
    "> * Mention 3 encodings that are difficult for the human eye to parse. Can you find an example of a visualization online that uses one of those three?\n",
    "> * Explain in your own words: What is the problem with pie-charts?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Visualizing geo-data\n",
    "\n",
    "It turns out that `plotly` (which we used during Week 2) is not the only way of working with geo-data. There are many different ways to go about it. (The hard-core PhD and PostDoc researchers in my group simply use matplotlib, since that provides more control. For an example of that kind of thing, check out [this tutorial](https://towardsdatascience.com/visualizing-geospatial-data-in-python-e070374fe621).)\n",
    "\n",
    "Today, we'll try another library for geodata called [Folium](https://github.com/python-visualization/folium). It's good for you all to try out a few different libraries - remember that data visualization and analysis in Python is all about the ability to use many different tools. \n",
    "\n",
    "The exercise below is based on the code illustrated in this nice [tutorial](https://www.kaggle.com/daveianhickey/how-to-folium-for-maps-heatmaps-time-data), so let us start by taking a look at that one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Reading*. Read through the following tutorial\n",
    " * \"How to: Folium for maps, heatmaps & time data\". Get it here: https://www.kaggle.com/daveianhickey/how-to-folium-for-maps-heatmaps-time-data\n",
    " * (Optional) There are also some nice tricks in \"Spatial Visualizations and Analysis in Python with Folium\". Read it here: https://towardsdatascience.com/data-101s-spatial-visualizations-and-analysis-in-python-with-folium-39730da2adf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *Exercise*: A different take on geospatial data. \n",
    ">\n",
    ">A couple of weeks ago (Part 3 of Week 2), we worked with spacial data by using color-intensity of shapefiles to show the counts of certain crimes within those individual areas. Today, we look at studying geospatial data by plotting raw data points as well as heatmaps on top of actual maps.\n",
    "> \n",
    "> * First start by plotting a map of San Francisco with a nice tight zoom. Simply use the command `folium.Map([lat, lon], zoom_start=13)`, where you'll have to look up San Francisco's longitude and latitude.\n",
    "> * Next, use the the coordinates for SF City Hall `37.77919, -122.41914` to indicate its location on the map with a nice, pop-up enabled maker. (In the screenshot below, I used the black & white Stamen tiles, because they look cool).\n",
    "> <img src=\"https://raw.githubusercontent.com/suneman/socialdata2022/main/files/city_hall_2022.png\" alt=\"drawing\" width=\"600\"/>\n",
    "> * Now, let's plot some more data (no need for pop-ups this time). Select a couple of months of data for `'DRUG/NARCOTIC'` and draw a little dot for each arrest for those two months. You could, for example, choose June-July 2016, but you can choose anything you like - the main concern is to not have too many points as this uses a lot of memory and makes Folium behave non-optimally. \n",
    "> We can call this kind of visualization a *point scatter plot*.\n",
    "\n",
    "Ok. Time for a little break. Note that a nice thing about Folium is that you can zoom in and out of the maps.\n",
    "\n",
    "> *Exercise*: Heatmaps.\n",
    "> * Now, let's play with **heatmaps**. You can figure out the appropriate commands by grabbing code from the main [tutorial](https://www.kaggle.com/daveianhickey/how-to-folium-for-maps-heatmaps-time-data)) and modifying to suit your needs.\n",
    ">    * To create your first heatmap, grab all arrests for the category `'SEX OFFENSES, NON FORCIBLE'` across all time. Play with parameters to get plots you like.\n",
    ">    * Now, comment on the differences between scatter plots and heatmaps. \n",
    ">.      - What can you see using the scatter-plots that you can't see using the heatmaps? \n",
    ">.      - And *vice versa*: what does the heatmaps help you see that's difficult to distinguish in the scatter-plots?\n",
    ">    * Play around with the various parameters for heatmaps. You can find a list here: https://python-visualization.github.io/folium/plugins.html\n",
    ">    * Comment on the effect on the various parameters for the heatmaps. How do they change the picture? (at least talk about the `radius` and `blur`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the final element of working with heatmaps, let's now use the cool Folium functionality `HeatMapWithTime` to create a visualization of how the patterns of your favorite crime-type changes over time.\n",
    "\n",
    "> *Exercise*: Heatmap movies. This exercise is a bit more independent than above - you get to make all the choices.\n",
    "> * Start by choosing your favorite crimetype. Prefereably one with spatial patterns that change over time (use your data-exploration from the previous lectures to choose a good one).\n",
    "> * Now, choose a time-resolution. You could plot daily, weekly, monthly datasets to plot in your movie. Again the goal is to find interesting temporal patterns to display. We want at least 20 frames though.\n",
    "> * Create the movie using `HeatMapWithTime`.\n",
    "> * Comment on your results: \n",
    ">   - What patterns does your movie reveal?\n",
    ">   - Motivate/explain the reasoning behind your choice of crimetype and time-resolution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Errors in the data. The importance of looking at raw (or close to raw) data.\n",
    "\n",
    "We started the course by plotting simple histogram and bar plots that showed a lot of cool patterns. But sometimes the binning can hide imprecision, irregularity, and simple errors in the data that could be misleading. In the work we've done so far, we've already come across at least three examples of this in the SF data. \n",
    "\n",
    "1. In the temporal activity for `PROSTITUTION` something surprising is going on on Thursday. Remind yourself [**here**](https://raw.githubusercontent.com/suneman/socialdata2022/main/files/prostitution.png), where I've highlighted the phenomenon I'm talking about.\n",
    "2. Last week, when we investigated the details of how the timestamps are recorded using jitter-plots in the DAOST exercises, we saw that many more crimes were recorded e.g. on the hour, 15 minutes past the hour, and to a lesser in whole increments of 10 minutes. Crimes didn't appear to be recorded as frequently in between those round numbers. Remind yourself [**here**](https://raw.githubusercontent.com/suneman/socialdata2022/main/files/jitter.png), where I've highlighted the phenomenon I'm talking about.\n",
    "3. Also, the *Hall of Justice* on the 800 block of Bryant street seems to be an unlikely hotspot for sex offences. Take a look here [**here**](https://raw.githubusercontent.com/suneman/socialdata2022/main/files/crime_hot_spot.png).\n",
    "\n",
    "> *Exercise*: Data errors. The data errors we discovered above become difficult to notice when we aggregate data (and when we calculate mean values, as well as statistics more generally). Thus, when we visualize, errors become difficult to notice when binning the data. We explore this process in the exercise below.\n",
    ">\n",
    ">This last exercise for today has two parts:\n",
    "> * In each of the examples above, describe in your own words how the data-errors I call attention to above can bias the binned versions of the data. Also, briefly mention how not noticing these errors can result in misconceptions about the underlying patterns of what's going on in San Francisco (and our modeling).\n",
    "> * Find your own example of human noise in the data and visualize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
